{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akm2208/Aayushi-First-Files/blob/main/posch_tutorial_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installations\n",
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "t8LxV68ONUeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44fd99f3-1311-46ad-8ffc-2b0330dffafb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.11.17)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.9 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6C1aiVe7L0ze"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "import rasterio\n",
        "from rasterio.warp import reproject\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drive file structure - mount and change to directory of the notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "os.chdir('/content/gdrive/My Drive/Tutorial_Jan25_Satellite_ML/notebooks')"
      ],
      "metadata": {
        "id": "hXskV2qR1S1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8381752a-8905-49e4-862f-bd463a39dcd4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function to read in raster data."
      ],
      "metadata": {
        "id": "Cz_5jU1J963Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_one_raster(path):\n",
        "    # file is expected in bil format (or any rasterio-compatible format)\n",
        "\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read(1)\n",
        "        crs = src.crs\n",
        "        affine = src.transform\n",
        "\n",
        "    return arr, crs, affine # return the other things in order to post-verify\n",
        "                         # that everything happened properly"
      ],
      "metadata": {
        "id": "L0U1xU3e900p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in one temperature raster:"
      ],
      "metadata": {
        "id": "42v6OQe_uvU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '../data/temperature/prism_raw'\n",
        "YYYYMM = '201803'\n",
        "file = f'PRISM_tmax_stable_4kmM3_{YYYYMM}_bil.bil'\n",
        "path = f'{folder}/{file}'"
      ],
      "metadata": {
        "id": "3_52Nker92kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr, crs, affine = read_one_raster(path)"
      ],
      "metadata": {
        "id": "XGn-9wDgstLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore what these look like - arr, crs, affine"
      ],
      "metadata": {
        "id": "gXUbgXPf4qkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr"
      ],
      "metadata": {
        "id": "Kf-Ob0-u5G2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(arr)"
      ],
      "metadata": {
        "id": "oVqA4FxW5dgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crs"
      ],
      "metadata": {
        "id": "1s8HxSWcstNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "affine"
      ],
      "metadata": {
        "id": "_dzkgWfhstSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in all the temperature data that we care about. Put them in nice lists."
      ],
      "metadata": {
        "id": "RA4U0r5A5RSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will have temperature data from years 2018 thru 2022, and for each year use months 03 thru 08."
      ],
      "metadata": {
        "id": "U9wUlurrstU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_monthly_temp_paths(years=['2018','2019','2020','2021','2022'],\n",
        "                          months=['03','04','05','06','07','08'],\n",
        "                          folder='../data/temperature/prism_raw'):\n",
        "    YYYYMMs = []\n",
        "    for year in years:\n",
        "        for month in months:\n",
        "            YYYYMMs.append(year + month)\n",
        "    files = [f'PRISM_tmax_stable_4kmM3_{YYYYMM}_bil.bil' for YYYYMM in YYYYMMs]\n",
        "    paths = [f'{folder}/{file}' for file in files]\n",
        "\n",
        "    return YYYYMMs, paths # list of all paths"
      ],
      "metadata": {
        "id": "N2icZAJS92pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_paths(paths):\n",
        "    arrs = []\n",
        "    crss = []\n",
        "    affines = []\n",
        "    for path in paths:\n",
        "        arr, crs, affine = read_one_raster(path)\n",
        "        arrs.append(arr)\n",
        "        crss.append(crs)\n",
        "        affines.append(affine)\n",
        "\n",
        "    return arrs, crss, affines"
      ],
      "metadata": {
        "id": "mc39VJjYaVtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YYYYMMs, prism_paths = get_monthly_temp_paths(years=['2018','2019','2020','2021','2022'],\n",
        "                          months=['03','04','05','06','07','08'],\n",
        "                          folder='../data/temperature/prism_raw')\n",
        "\n",
        "prism_arrs, prism_crss, prism_affines = get_data_from_paths(prism_paths)"
      ],
      "metadata": {
        "id": "_jkn4wAwbiu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that all the CRSs and all the Affines are the same."
      ],
      "metadata": {
        "id": "ZrrXAJHL6Fdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def confirm_affines_same(affines):\n",
        "    if len(set(affines)) == 1:\n",
        "        print('Yes all affines same')\n",
        "    else:\n",
        "        print('No not same, checking what the affines are...')\n",
        "        print(set(affines))\n",
        "        print('If the above are within a tiny error you\\'re good,')\n",
        "        print('otherwise, go back and match your affines.')"
      ],
      "metadata": {
        "id": "JKb_WgR2rhVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confirm_crss_same(crss):\n",
        "    if len(set(crss)) == 1:\n",
        "        print('Yes all CRSs same')\n",
        "    else:\n",
        "        print('No not same, checking what the CRSs are...')\n",
        "        print(set(crss))\n",
        "        print('If the above are actually the same CRS you\\'re good,')\n",
        "        print('otherwise, go back and match your CRSs.')"
      ],
      "metadata": {
        "id": "vp_erIhSrjuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confirm_affines_same(prism_affines)"
      ],
      "metadata": {
        "id": "ngm88yBd6Pha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confirm_crss_same(prism_crss)"
      ],
      "metadata": {
        "id": "pjEJK87efbiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in one surface reflectance raster."
      ],
      "metadata": {
        "id": "W2Sf9TnO6Qiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '../data/surface_reflectance/hls_raw'\n",
        "file = 'HLS.S30.T10SFH.2018285T185321.v2.0/HLS.S30.T10SFH.2018285T185321.v2.0.B03.tif'\n",
        "# B03 means Green color band. (B02 is blue, B04 is red, etc)\n",
        "# 2018285 means Year 2018 Day 285. So this is in October.\n",
        "path = f'{folder}/{file}'"
      ],
      "metadata": {
        "id": "8yR4EsW46gmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr, crs, affine = read_one_raster(path)"
      ],
      "metadata": {
        "id": "yeEkOE6iH0qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr"
      ],
      "metadata": {
        "id": "BcWpIm7JHq3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(arr)"
      ],
      "metadata": {
        "id": "-dmCidBRHrsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crs"
      ],
      "metadata": {
        "id": "3quaVbscHuA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "affine"
      ],
      "metadata": {
        "id": "P2DaZcR6HvZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in all the surface reflectance data we care about."
      ],
      "metadata": {
        "id": "G8xrmEtu6g78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hls_folder = '../data/surface_reflectance/hls_raw'\n",
        "hls_files = ['HLS.S30.T10SFH.2018285T185321.v2.0/HLS.S30.T10SFH.2018285T185321.v2.0.B03.tif',\n",
        "         'HLS.S30.T10SFH.2019285T185319.v2.0/HLS.S30.T10SFH.2019285T185319.v2.0.B03.tif',\n",
        "         'HLS.S30.T10SFH.2020285T185321.v2.0/HLS.S30.T10SFH.2020285T185321.v2.0.B03.tif',\n",
        "         'HLS.S30.T10SFH.2021284T185319.v2.0/HLS.S30.T10SFH.2021284T185319.v2.0.B03.tif',\n",
        "         'HLS.S30.T10SFH.2022284T185321.v2.0/HLS.S30.T10SFH.2022284T185321.v2.0.B03.tif']\n",
        "hls_paths = [f'{hls_folder}/{file}' for file in hls_files]"
      ],
      "metadata": {
        "id": "lIGAV4pA6oqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sr_arrs, sr_crss, sr_affines = get_data_from_paths(hls_paths)"
      ],
      "metadata": {
        "id": "1XkVs8fPG_wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that all CRSs and all Affines are the same."
      ],
      "metadata": {
        "id": "hHOHQ93JIjpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confirm_crss_same(sr_crss)"
      ],
      "metadata": {
        "id": "n6j4ZT7JImxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confirm_affines_same(sr_affines)"
      ],
      "metadata": {
        "id": "XNUrpJrDIxI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reproject and aggregate the surface reflectance data to match the temperature data."
      ],
      "metadata": {
        "id": "e3GKpxUQ6ox6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reproject surface reflectance data\n",
        "\n",
        "end = rasterio.open(prism_paths[0])\n",
        "\n",
        "reprojected_hls_arrs = []\n",
        "reprojected_hls_affines = []\n",
        "\n",
        "for hls_path in hls_paths:\n",
        "    print(f'Working on HLS data {hls_path}...')\n",
        "    with rasterio.open(hls_path) as start:\n",
        "        array, affine = rasterio.warp.reproject(source=start.read(1), # this is the starting array\n",
        "                  destination=end.read(1), # the array of the end goal projection\n",
        "                  src_transform=start.transform, # this is the transform corresponding to start array\n",
        "                  src_crs=start.crs, # this is the crs corresponding to start array\n",
        "                  dst_transform=end.transform, # this is the transform corresponding to end array\n",
        "                  dst_crs=end.crs, # this is the crs corresponding to end array\n",
        "                  resampling=rasterio.enums.Resampling.average # aggregate temperature using average\n",
        "                  )\n",
        "\n",
        "    reprojected_hls_arrs.append(array)\n",
        "    reprojected_hls_affines.append(affine)\n",
        "\n",
        "print('Done.')"
      ],
      "metadata": {
        "id": "PTioAqMGJQz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at one of the reprojected arrays."
      ],
      "metadata": {
        "id": "q1pxXqw8j-kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# look at one\n",
        "reprojected_hls_arrs[0]"
      ],
      "metadata": {
        "id": "Z1g-EJfVjxCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(reprojected_hls_arrs[0])"
      ],
      "metadata": {
        "id": "rad9GfAlkH8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(reprojected_hls_arrs[0][250:300,75:125])\n",
        "# Exercise: take a look at all 5 hls arrays (just change the index from 0 to 1 to 2 etc)"
      ],
      "metadata": {
        "id": "CUNteQf4SDcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bonus exercise: check that all the reprojected affines are the same as the PRISM temperature affines!"
      ],
      "metadata": {
        "id": "hua2wEX-j-At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a numpy array in machine learning format."
      ],
      "metadata": {
        "id": "kKILE_Mj6_Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, create a Boolean mask of the Sacramento area (the tile where we have HLS data)\n",
        "sacramento = reprojected_hls_arrs[0] != 0.  # when we reprojected, the rest of USA was set to 0"
      ],
      "metadata": {
        "id": "_Q0r6ULi7Fkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note how many grid cells we have in our study area\n",
        "sum(sum(sacramento))"
      ],
      "metadata": {
        "id": "vDzwE_92PpS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create ML features for year 2018\n",
        "# 6 features (temperature in March, April, ..., August)\n",
        "features_2018 = []\n",
        "for arr in prism_arrs[:6]:\n",
        "    feature = arr[sacramento] # grab only the grid cells in our study area\n",
        "    features_2018.append(feature)\n",
        "\n",
        "# stack them into a numpy array - this is X for our 2018 data.\n",
        "X_2018 = np.column_stack(features_2018)"
      ],
      "metadata": {
        "id": "UG7oY978UicS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at it to see that it worked\n",
        "X_2018"
      ],
      "metadata": {
        "id": "3XPHw-FEc6JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_2018.shape  # check that there are 719 observations (rows) and 6 features (columns)"
      ],
      "metadata": {
        "id": "C-z9f04jdDOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create ML features X for years 2019, 2020, 2021, 2022\n",
        "features_2019 = []\n",
        "for arr in prism_arrs[6:12]:\n",
        "    feature = arr[sacramento] # grab only the grid cells in our study area\n",
        "    features_2019.append(feature)\n",
        "X_2019 = np.column_stack(features_2019)\n",
        "\n",
        "features_2020 = []\n",
        "for arr in prism_arrs[12:18]:\n",
        "    feature = arr[sacramento] # grab only the grid cells in our study area\n",
        "    features_2020.append(feature)\n",
        "X_2020 = np.column_stack(features_2020)\n",
        "\n",
        "features_2021 = []\n",
        "for arr in prism_arrs[18:24]:\n",
        "    feature = arr[sacramento] # grab only the grid cells in our study area\n",
        "    features_2021.append(feature)\n",
        "X_2021 = np.column_stack(features_2021)\n",
        "\n",
        "features_2022 = []\n",
        "for arr in prism_arrs[24:30]:\n",
        "    feature = arr[sacramento] # grab only the grid cells in our study area\n",
        "    features_2022.append(feature)\n",
        "X_2022 = np.column_stack(features_2022)"
      ],
      "metadata": {
        "id": "SZyysy5xWZLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create ML targets y for years 2018-2022\n",
        "y_2018 = reprojected_hls_arrs[0][sacramento]\n",
        "y_2019 = reprojected_hls_arrs[1][sacramento]\n",
        "y_2020 = reprojected_hls_arrs[2][sacramento]\n",
        "y_2021 = reprojected_hls_arrs[3][sacramento]\n",
        "y_2022 = reprojected_hls_arrs[4][sacramento]"
      ],
      "metadata": {
        "id": "ao_23lvnezwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stack years 2018-2021 into X_train and y_train\n",
        "# need to stack verticvally (row-wise) - end result has 6 features a couple thousand observations\n",
        "X_train = np.row_stack([X_2018,X_2019,X_2020,X_2021])\n",
        "y_train = np.concatenate([y_2018,y_2019,y_2020,y_2021])\n",
        "\n",
        "# confirm we ended up with the correct shape\n",
        "print('X_train has shape', X_train.shape)\n",
        "print('y_train has shape', y_train.shape)"
      ],
      "metadata": {
        "id": "aSuAZ7eYhCRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use 2022 data for our validation set\n",
        "X_val = X_2022\n",
        "y_val = y_2022\n",
        "\n",
        "# confirm we ended up with the correct shape\n",
        "print('X_val has shape', X_val.shape)\n",
        "print('y_val has shape', y_val.shape)"
      ],
      "metadata": {
        "id": "0fbOIDkbjmCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hooray! Now we have a nice formatted dataset!"
      ],
      "metadata": {
        "id": "xeOu2CjGkm3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bonus exercise: do exploratory data analysis on our training dataset. E.g. histogram of March temperatures."
      ],
      "metadata": {
        "id": "d5tf7SEZlVlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do some machine learning."
      ],
      "metadata": {
        "id": "kRGHZBoo7Fr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a (not-yet-fitted) linear regression model\n",
        "linreg01 = LinearRegression() # we will use default hyperparameters\n",
        "\n",
        "# fit the model to our training data\n",
        "linreg01.fit(X_train, y_train)\n",
        "\n",
        "# make predictions based on our validation X\n",
        "y_pred = linreg01.predict(X_val)\n",
        "\n",
        "# compare predictions to ground truth by calculating a metric\n",
        "linreg01_rmse = np.sqrt(np.mean((y_val - y_pred)**2)) # RMSE is Root Mean Square Error"
      ],
      "metadata": {
        "id": "u0ijccd47QXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linreg01_rmse"
      ],
      "metadata": {
        "id": "n-qrQLLzn_G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a (not-yet-fitted) random forest model\n",
        "forest01 = RandomForestRegressor() # we will use default hyperparameters\n",
        "\n",
        "# fit the model to our training data\n",
        "forest01.fit(X_train, y_train)\n",
        "\n",
        "# make predictions based on our validation X\n",
        "y_pred = forest01.predict(X_val)\n",
        "\n",
        "# compare predictions to ground truth by calculating a metric\n",
        "forest01_rmse = np.sqrt(np.mean((y_val - y_pred)**2)) # RMSE is Root Mean Square Error"
      ],
      "metadata": {
        "id": "8r108eQ4n9_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest01_rmse"
      ],
      "metadata": {
        "id": "6DG9iy03po_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE describes, on average, how far off the model's predictions of reflectance are from the ground truth reflectance.\n",
        "\n",
        "The default Random Forest performed better than the default Linear Regression.\n",
        "\n",
        "Next: try some more models! Try different hyperparameters!"
      ],
      "metadata": {
        "id": "dAQzjUQqp0jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: try an Extra Trees model - class ExtraTreesRegressor() - and see if it performs better."
      ],
      "metadata": {
        "id": "o3ycYovtqrvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note on Scaling: LinearRegression(), RandomForestRegressor(), and ExtraTreesRegressor() do not require scaling of the data. Many other models in scikit-learn do require scaling - your go-to should be StandardScaler(). Scaling your data is just one extra line of code before you fit your model to your data."
      ],
      "metadata": {
        "id": "kVa5yfnhrqk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your next science question should be \"Is this performance even good?\" Relative to other studies? Relative to what is useful?\n",
        "\n",
        "You should also ask \"What else could be done to improve this study?\" For example, we would like to control greenness for plant type, as some plants are naturally more green than others."
      ],
      "metadata": {
        "id": "sXOJmoZmsrFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's all for today - thanks for participating!\n",
        "\n",
        "If you have questions outside of the tutorial session, please reach out: posch.au@northeastern.edu and WhatsApp.\n",
        "\n",
        "-August"
      ],
      "metadata": {
        "id": "lnlZkk2ot-_I"
      }
    }
  ]
}